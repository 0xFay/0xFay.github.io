# 爬虫学习


---
>这几天想加深一下python的学习，就想着写个简单的爬虫来学习学习。爬的是p站的图片（指pixiv...好8其实也差不多），绝对不是为了ghs！

写下思路，我引用了requests和beautifulsoup4
requests是为了请求网站而beautifulsoup4是为了提取网站内容，requests也可以用urllib库来代替，不过我没用过urllib库，而且好像requests比urllib来的更简单，之后有时间会去了解urllib库。其实本来也想用正则表达式去过滤内容的，不过学着学着了解到了bs4这个东西，突然感觉这玩意儿比正则简单多了，不过写完这个还会继续学正则表达式（毕竟正则无论是在题还是在实践还是用途挺广的）。

我的目标是爬p站的日榜图片，先是收集相关的信息，比如p站日榜的url是<br>`https://www.pixiv.net/ranking.php?mode=daily`<br>然后发现p站日榜中的图片的地址，比如这个<br>`https://i.pximg.net/c/240x480/img-master/img/2019/12/18/20/58/20/78357442_p0_master1200.jpg`<br>不过这个图片是缩略图，很模糊，也很小，我们就要去找原图地址。点开日榜的图片，再找图片的来源，这时就得到了图片的原图地址<br>`https://i.pximg.net/img-master/img/2019/12/18/20/58/20/78357442_p0_master1200.jpg`<br>可以很明确的看出他和上面那个链接的差别仅是url中少了一个<br>`/c/240x480`<br>我们就不用每个都去单独读取了，直接获取日榜所有缩略图的地址再把地址改成原图地址就行了。还有什么值得注意的地方的话，就是在请求图片地址的时候，需要添加referer头和user-agent头，p站会验证请求头以防止盗链，否则会403forbidden（这个地方还卡了我好一会儿...）把源码贴出来<br>
```
import requests
from bs4 import BeautifulSoup
import time
import os
#目前想要实现内容包括
#下载指定天日的日榜图片(暂时没找到之前的日榜，不知道是不是每日更新还是保存到了一个地方)
#选择日榜月榜

Referer='http://www.pixiv.net/member_illust.php?mode=medium&illust_id=here'
url='https://www.pixiv.net/ranking.php?mode=daily'#日榜

print("=====================================================================================================")
print("|           _________          ______    ____       _____         ______      _______     ______    |")
print("|          |---------\        |------|   \---\     /----/        |------|     |-----/    /-----/    |")
print("|           |--|   \---\       |---|       \--\   /---/           |---|       |---/     /---/       |")
print("|           |-|     |---|      |--|         \--\/---/             |--|        /--/    /---/         |")
print("|          |--|    /---/      |--|           |-- -/              |--|        /--/   /---/           |")
print("|         |----------/       |--|           /----\              |--|        /--/  /---/             |")
print("|        |---|              |--|           /--/ \--\           |--|        /--/ /---/               |")
print("|       |---|              |--|          /---/   \--\         |--|        /-------/                 |")
print("|      |---|             |-----|        /---/    |---\      |----|       /------/                   |")
print("|     |-----|           |-------|      /----\    /----\    |------|     /-----/                     |")
print("|                                                                                                   |")
print("=====================================================================================================")



r=requests.get(url)
soup=BeautifulSoup(r.text,'html.parser')


def getReferer(url):#构造要访问图片的 reference 头
    idname=url[55:63]#得到图片id
    url=Referer.replace('here',idname)#替换为图片地址
    
def mkdir(path):#创建文件夹
    path=path.strip()
    path=path.rstrip("\\")
    isExists=os.path.exists(path)
    if not isExists:
        os.makedirs(path)
        return True
    else:
        return False


def download(url):#下载图片到指定文件夹并用时间和id命名
    ttt=getReferer(url)
    img_headers = {#构造请求头
                'Referer': 'http://www.pixiv.net/member_illust.php?mode=medium&illust_id='
                ,
                'User-Agent': "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/" +
                              "537.36 (KHTML, like Gecko) Chrome/50.0.2661.87 Safari/537.36"
                              }
    website=requests.get(url,headers=img_headers)
    date=time.strftime("%Y-%m-%d", time.localtime())
    name=url[35:39]+url[40:42]+url[43:45]+url[46:48]+url[49:51]+url[52:54]+'_'+url[55:63]
    path='F:/P站图片/'+date
    mkdir(path)
    with open('F:/P站图片/'+date+'/'+name+'.jpg', 'wb') as f:#下载图片
        f.write(website.content)
        print('下载完成')

    
def correct_url(url):#改为原图路径
    url=url.replace('c/240x480/','')
    print(url)

for link in soup.find_all('img'):#获取日榜的图片url
    l=link.get('data-src')
    l=l.replace('c/240x480/','')#这里将缩略图的地址换为原图的地址
    print(l)
    download(l)

print('今日日榜下载完成，明天再来哦~')
```
<br>目前还有点想实现的功能还没实现，改完会进行修改，还有就是...这个脚本实在不怎么美观...如果有什么修改意见可以留言嗷~（这是我写的第一个爬虫，敬请指教！）

PS：修改了一下，加了os库和time库，方便归类每一天的日榜图片